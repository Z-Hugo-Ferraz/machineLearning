{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"arvore/main/","title":"\u00c1rvore de Decis\u00e3o","text":""},{"location":"arvore/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de \u00e1rvore de decis\u00e3o.</p>"},{"location":"arvore/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"arvore/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-10-26T23:09:04.708206 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> 2025-10-26T23:09:04.795153 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-10-26T23:09:04.829930 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-10-26T23:09:04.871001 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual e n\u00e3o apresenta binariedade, a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-10-26T23:09:04.948945 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel. E como esta coluna n\u00e3o apresentar binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais e nulos em valores n\u00famericos. </p> 2025-10-26T23:09:04.990837 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-10-26T23:09:05.039639 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-10-26T23:09:05.132513 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-10-26T23:09:05.225765 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-10-26T23:09:05.337658 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"arvore/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa major race gmat work_exp work_industry admission 0 3.38 2 4 680 7 3 Refused 1 3.24 0 5 630 7 9 Refused 1 2.99 1 2 620 6 0 Refused 0 3.09 1 5 600 8 1 Refused 0 3.18 2 2 680 7 1 Refused 1 3.29 2 2 690 5 11 Refused 1 3.19 1 1 630 5 8 Refused 1 3.2 1 0 640 4 13 Refused 0 3.3 2 0 590 4 10 Refused <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 3568 Male False 3.44 Business White 740 5 Financial Services nan 5532 Male False 3.24 Business Asian 700 6 Technology nan 3538 Male False 3.37 Business White 620 5 Financial Services nan 1740 Male False 3.24 Business White 640 4 Health Care nan 4231 Male False 3.16 Business White 690 4 Health Care nan 5956 Female False 3.16 STEM Hispanic 640 5 Nonprofit/Gov nan 5583 Male True 3.18 STEM nan 670 5 Consulting nan 908 Male False 2.93 Business White 610 3 Technology nan 907 Male True 3.19 Humanities nan 680 7 Consulting nan"},{"location":"arvore/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nlabel_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=27, stratify=y)\n</code></pre>"},{"location":"arvore/main/#treinamento-da-arvore","title":"Treinamento da \u00c1rvore","text":"Modelo da \u00c1rvorecode <p>Precis\u00e3o da Valida\u00e7\u00e3o: 0.7811 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 1 gpa 0.288516 4 gmat 0.275600 6 work_industry 0.167499 5 work_exp 0.106820 3 race 0.073188 2 major 0.070763 0 gender 0.017615 2025-10-26T23:09:07.289594 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\ny_pred = classifier.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o da Valida\u00e7\u00e3o: {accuracy:.4f}\")\n\nfeature_importance = pd.DataFrame({\n    'Feature': classifier.feature_names_in_,\n    'Import\u00e2ncia': classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n\nplt.figure(figsize=(20, 10))\ntree.plot_tree(classifier, max_depth=5, fontsize=10)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"arvore/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Com este treinamento o modelo apresenta 78.48% de precis\u00e3o, n\u00famero satisfat\u00f3rio para um modelo de classifica\u00e7\u00e3o real, e as colunas mais importantes em sua tomada de deicis\u00e3o s\u00e3o as ponuta\u00e7\u00f5es gpa e gmat com 29.4% e 27.7% de import\u00e2ncia, respectivamente, e a coluna com menor relevancia para o modelo \u00e9 a gender, com  1.7% de import\u00e2ncia.</p> <p>Entretando utilizar mais dados no treinamento do modelo poderia melhorara sua precis\u00e3o. Logo, para compravar esta hip\u00f3tese o modelo ser\u00e1 treinado novamente com 80% da base de dados original para treinamento.</p>"},{"location":"arvore/main/#retreinamento","title":"Retreinamento","text":"Modelo da \u00c1rvorecode <p>Precis\u00e3o da Valida\u00e7\u00e3o: 0.7780 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 1 gpa 0.324860 4 gmat 0.299806 6 work_industry 0.129459 3 race 0.089034 5 work_exp 0.087875 2 major 0.052423 0 gender 0.016543 2025-10-26T23:09:08.135622 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\ny_pred = classifier.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o da Valida\u00e7\u00e3o: {accuracy:.4f}\")\n\nfeature_importance = pd.DataFrame({\n    'Feature': classifier.feature_names_in_,\n    'Import\u00e2ncia': classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n\nplt.figure(figsize=(20, 10))\ntree.plot_tree(classifier, max_depth=5, fontsize=10)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"arvore/main/#avaliacao-do-novo-modelo","title":"Avalia\u00e7\u00e3o do novo modelo","text":"<p>Com este retreinamento a hip\u00f3tese anterior \u00e9 rejeitada, pois ao utilizar 80% da base para treinamento a precis\u00e3o geral do modelo caiu para 77.89%. Entretanto, as m\u00e9tricas de gpa e gmat continuaram sendo as mais relevantes, comprovando sua import\u00e2ncia para o modelo.</p>"},{"location":"arvore/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Ao fim deste roteiro nota-se que as colunas n\u00e3o precisam estar normalizadas para que se treine uma \u00e1rvore de decis\u00e3o, aumentar os dados de treinamento do modelo, em detrimento dos dados de teste, pode prejudicar a precis\u00e3o geral do mesmo e que grande parte do tempo de trabalho do cientista de dados \u00e9 a an\u00e1lise e limpeza da base de dados original.  </p>"},{"location":"kmeans/main/","title":"K-Means","text":""},{"location":"kmeans/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de K-Means.</p>"},{"location":"kmeans/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"kmeans/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-10-26T23:09:08.873808 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> 2025-10-26T23:09:08.956129 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-10-26T23:09:08.990156 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-10-26T23:09:09.029087 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual, n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 2 vari\u00e1veis dummies.</p> 2025-10-26T23:09:09.106279 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel, e gerar dummies para cada valor registrado na coluna, pois esta n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"). </p> 2025-10-26T23:09:09.148537 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-10-26T23:09:09.198931 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-10-26T23:09:09.290451 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 13 vari\u00e1veis dummies.</p> 2025-10-26T23:09:09.396033 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-10-26T23:09:09.510043 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"kmeans/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa gmat work_exp admission race_Black race_Hispanic race_Other race_White race_international major_Humanities major_STEM work_industry_Consulting work_industry_Energy work_industry_Financial Services work_industry_Health Care work_industry_Investment Banking work_industry_Investment Management work_industry_Media/Entertainment work_industry_Nonprofit/Gov work_industry_Other work_industry_PE/VC work_industry_Real Estate work_industry_Retail work_industry_Technology 1 -0.00470929 -0.630806 -0.985085 Refused False False False False False True False False False False False True False False False False False False False False 1 -0.202691 2.20947 0.952244 Refused False True False False False True False False False False False False False False False False False False False True 0 -0.862632 -0.0221743 1.92091 Refused False False False False True True False False False False False False False False True False False False False False 0 0.391255 0.180703 0.952244 Refused False False False False False False True False False False False False False False False False False False False True 1 -1.45658 0.180703 0.952244 Refused False False False True False True False False False False False False False False True False False False False False 0 0.391255 1.39797 0.952244 Refused False False False False True False True False False False False False False False False False True False False False 0 0.193273 0.38358 2.88957 Admit False False False True False True False True False False False False False False False False False False False False 0 -2.57848 -1.64519 -0.0164207 Refused False False False True False False True False False False False False False False False True False False False False 1 -0.00470929 0.38358 -0.985085 Refused False False False False True False False False False False False False False False False False True False False False <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 3112 Male False 3.22 STEM Hispanic 710 4 Technology nan 5865 Male False 3.39 Humanities White 670 6 Financial Services nan 4842 Male False 2.99 Humanities White 630 4 Investment Banking nan 5402 Male False 3.18 Business Black 670 5 Technology nan 1484 Female False 3.37 STEM Asian 660 5 PE/VC nan 4571 Male False 3.4 Business Asian 650 7 PE/VC nan 229 Male True 3.39 Humanities nan 650 6 Other nan 6118 Male False 3.45 STEM Other 750 6 Health Care Admit 1486 Female True 3.24 STEM nan 690 5 Other nan"},{"location":"kmeans/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n</code></pre>"},{"location":"kmeans/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"Treinamentocode <pre><code>import base64\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Carregar os dados\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n# Excluir as colunas n\u00e3o desejadas\ndf = df.drop(columns=[\"application_id\", \"international\"])\n\n# Preencher valores nulos\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n# Label encoding da coluna em texto bin\u00e1ria\nlabel_encoder = LabelEncoder()\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n# Escalonar vari\u00e1veis cont\u00ednuas\nscaler = StandardScaler()\ndf[[\"gpa\", \"gmat\", \"work_exp\"]] = scaler.fit_transform(df[[\"gpa\", \"gmat\", \"work_exp\"]])\n\n# Gerar dummies\ndf = pd.get_dummies(df, columns=[\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n# Separar vari\u00e1veis independentes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reduzir para 2 dimens\u00f5es com PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_train)\n\n# Treinar KMeans\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Plot\nplt.figure(figsize=(12, 10))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"viridis\", s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c=\"red\", marker=\"*\", s=200, label=\"Centroids\")\nplt.title(\"K-Means Clustering Results (PCA 2D)\")\nplt.xlabel(\"PCA Feature 1\")\nplt.ylabel(\"PCA Feature 2\")\nplt.legend()\n\n# Salvar em buffer png\nbuffer = BytesIO()\nplt.savefig(buffer, format=\"png\", transparent=True, bbox_inches=\"tight\")\nbuffer.seek(0)\n\n# Converter em base64\nimg_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n\n# Criar tag HTML para embutir no MkDocs\nhtml_img = f'&lt;img src=\"data:image/png;base64,{img_base64}\" alt=\"KMeans clustering\" /&gt;'\n\nprint(html_img)\n</code></pre>"},{"location":"kmeans/main/#avaliacao","title":"Avalia\u00e7\u00e3o","text":"Treinamentocode <p>Acur\u00e1cia: 84.14% Matriz de Confus\u00e3o:</p> Classe Pred 0 Classe Pred 1 Classe Pred 2 Classe Real 0 0 704 0 Classe Real 1 0 4169 0 Classe Real 2 0 82 0 <pre><code>import pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\nfrom scipy.stats import mode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Carregar os dados\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n# Excluir as colunas n\u00e3o desejadas\ndf = df.drop(columns=[\"application_id\", \"international\"])\n\n# Preencher valores nulos\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n# Label encoding da coluna em texto bin\u00e1ria\nlabel_encoder = LabelEncoder()\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n# Escalonar vari\u00e1veis cont\u00ednuas\nscaler = StandardScaler()\ndf[[\"gpa\", \"gmat\", \"work_exp\"]] = scaler.fit_transform(df[[\"gpa\", \"gmat\", \"work_exp\"]])\n\n# Gerar dummies\ndf = pd.get_dummies(df, columns=[\"race\", \"major\", \"work_industry\"], drop_first=True)\n\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reduzir para 2 dimens\u00f5es com PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_train)\n\n# Treinar KMeans\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Mapear clusters para classes reais por voto majorit\u00e1rio\ncluster_map = {}\nfor c in np.unique(labels):\n    mask = labels == c\n    majority_class = mode(y_train[mask], keepdims=False)[0]\n    cluster_map[c] = majority_class\n\n# Reatribuir clusters como classes previstas\ny_pred = np.array([cluster_map[c] for c in labels])\n\n# Calcular acur\u00e1cia e matriz de confus\u00e3o\nacc = accuracy_score(y_train, y_pred)\ncm = confusion_matrix(y_train, y_pred)\n\ncm_df = pd.DataFrame(\n    cm,\n    index=[f\"Classe Real {cls}\" for cls in np.unique(y_train)],\n    columns=[f\"Classe Pred {cls}\" for cls in np.unique(y_train)]\n)\n\nprint(f\"Acur\u00e1cia: {acc*100:.2f}%\")\nprint(\"&lt;br&gt;Matriz de Confus\u00e3o:\")\nprint(cm_df.to_html())\n</code></pre>"},{"location":"kmeans/main/#analise","title":"An\u00e1lise","text":"<p>Apesar de atingir 84,14% de acur\u00e1cia, o modelo aparenta ser inadequado para a base, pois, ainda que tenha encontrado 3 clusters, estes n\u00e3o correspondem as classifica\u00e7\u00f5es desejadas, de maneira que, para todos os clusters, a maioria dos pontos possuem o r\u00f3tulo de <code>Refused</code>, fazendo com que todas as predi\u00e7\u00f5es sejam classificadas como <code>Refused</code>.</p>"},{"location":"knn/main/","title":"KNN","text":""},{"location":"knn/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de K-Nearest Neighbors (KNN).</p>"},{"location":"knn/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"knn/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-10-26T23:09:10.300563 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> 2025-10-26T23:09:10.380904 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-10-26T23:09:10.414299 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-10-26T23:09:10.454672 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual, n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 2 vari\u00e1veis dummies.</p> 2025-10-26T23:09:10.554528 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel, e gerar dummies para cada valor registrado na coluna, pois esta n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"). </p> 2025-10-26T23:09:10.599728 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-10-26T23:09:10.648078 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-10-26T23:09:10.739027 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 13 vari\u00e1veis dummies.</p> 2025-10-26T23:09:10.942869 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-10-26T23:09:11.055099 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"knn/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa gmat work_exp admission race_Black race_Hispanic race_Other race_White race_international major_Humanities major_STEM work_industry_Consulting work_industry_Energy work_industry_Financial Services work_industry_Health Care work_industry_Investment Banking work_industry_Investment Management work_industry_Media/Entertainment work_industry_Nonprofit/Gov work_industry_Other work_industry_PE/VC work_industry_Real Estate work_industry_Retail work_industry_Technology 1 1.18318 0.586457 -0.0164207 Refused True False False False False True False False False False False False False False False False False False False True 1 2.04111 0.38358 0.952244 Refused True False False False False False False True False False False False False False False False False False False False 1 -0.796638 -0.0221743 -0.985085 Refused False False False False True True False False False False False False False False False False True False False False 1 0.325261 -1.03656 -2.92241 Refused False False False False True False True False False False False False False False False False True False False False 1 0.787219 -1.44231 -0.985085 Refused False False True False False False True True False False False False False False False False False False False False 1 -1.06061 1.60084 -0.0164207 Refused False False False False True False True False False False False False False True False False False False False False 1 -0.334679 0.789334 -0.985085 Refused False False False False False False True False False False False False False False False False True False False False 0 0.259267 -0.833683 -0.0164207 Refused False False False False True True False True False False False False False False False False False False False False 0 -0.400673 -1.03656 -0.0164207 Refused False False False False True True False False False False False False False False False True False False False False <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 2279 Male True 3.58 STEM nan 700 5 Consulting Admit 1373 Female False 3.13 Business Black 610 5 Other nan 1606 Male False 3.23 STEM Black 740 5 Investment Banking nan 5687 Female False 3.34 Humanities Asian 640 4 CPG nan 2575 Female True 3.36 Humanities nan 710 6 Energy nan 1602 Male False 3.45 STEM Asian 680 3 Technology nan 6040 Male False 3.23 Humanities White 670 6 Consulting nan 5590 Male False 3.14 Business White 640 4 Investment Banking nan 5417 Female False 3.36 STEM Black 680 6 PE/VC nan"},{"location":"knn/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n</code></pre>"},{"location":"knn/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>A seguir, foi feito o treinamento do modelo utilizando os tr\u00eas vizinhos mais pr\u00f3ximos para a classifica\u00e7\u00e3o, ou seja <code>k = 4</code>, e foi utilizada a fun\u00e7\u00e3o <code>permutation_importance</code> para avaliar a import\u00e2ncia das features no modelo.</p> <p>Esta fun\u00e7\u00e3o realiza diversas itera\u00e7\u00f5es sequ\u00eanciais com a base de teste. Em cada uma das itera\u00e7\u00f5es, uma coluna da base de teste tem seus valores embaralhados, e o modelo tenta classifica-l\u00e1. Com as classifica\u00e7\u00f5es obtidas, esta fun\u00e7\u00e3o calcula a diferen\u00e7a na precis\u00e3o. Desta forma medindo a import\u00e2ncia de cada feature.</p> Modelocode <p>Accuracy: 0.79 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.013785 1 work_industry_Health Care 0.003349 2 race_international 0.003253 3 work_industry_Technology 0.000993 4 work_industry_Real Estate 0.000694 5 work_industry_Nonprofit/Gov 0.000557 6 work_industry_Media/Entertainment -0.000065 7 work_industry_Retail -0.000137 8 work_industry_Investment Banking -0.000202 9 work_industry_Investment Management -0.000557 10 gender -0.000597 11 work_industry_PE/VC -0.000718 12 work_industry_Energy -0.000799 13 major_Humanities -0.000856 14 race_Other -0.000944 15 race_Black -0.001001 16 race_Hispanic -0.001316 17 work_industry_Financial Services -0.001937 18 work_industry_Other -0.002171 19 major_STEM -0.002373 20 race_White -0.003890 21 gpa -0.005093 22 work_industry_Consulting -0.009023 23 work_exp -0.011913 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre>"},{"location":"knn/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Ao fim do treinamento o modelo apresentou 79% de precis\u00e3o, valor satisfat\u00f3rio. Entretanto algumas features apresentaram valores negativos no teste de <code>permutation_importance</code>, o que indica que o modelo ficaria mais preciso caso esta vari\u00e1vel n\u00e3o estivesse presente, por\u00e9m por se tratar de um valor muito pr\u00f3ximo a zero, este indicio pode ser apenas ru\u00eddo estat\u00edstico.</p>"},{"location":"knn/main/#retreinamento","title":"Retreinamento","text":"1\u00b0 retreino2\u00b0 retreino3\u00b0 retreino4\u00b0 retreino5\u00b0 retreino <p>A seguir foi feito o retreinamento do modelo sem a coluna \"work_exp\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.81 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.030517 1 gpa 0.012873 2 gender 0.009201 3 race_international 0.008805 4 race_Black 0.008394 5 major_STEM 0.007199 6 race_White 0.005634 7 work_industry_Consulting 0.004487 8 work_industry_PE/VC 0.004431 9 work_industry_Financial Services 0.003979 10 work_industry_Nonprofit/Gov 0.003277 11 race_Hispanic 0.003107 12 major_Humanities 0.002994 13 work_industry_Technology 0.002405 14 work_industry_Other 0.001953 15 work_industry_Energy 0.001574 16 work_industry_Real Estate 0.001533 17 work_industry_Investment Banking 0.001251 18 race_Other 0.001017 19 work_industry_Media/Entertainment 0.000831 20 work_industry_Retail -0.000032 21 work_industry_Health Care -0.001768 22 work_industry_Investment Management -0.002147 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo apresentou aumento de precis\u00e3o em dois pontos percentuais, portanto ser\u00e1 realizado o 2\u00b0 retreino, seguindo a mesma l\u00f3gica, ou seja, removendo a vari\u00e1vel com menor valor no teste de <code>permutation_importance</code>, desde que esta seja negativa.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\" e \"work_industry_Investment Management\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.82 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.036449 1 gpa 0.019580 2 race_Black 0.010807 3 work_industry_Consulting 0.010500 4 race_international 0.010291 5 gender 0.009968 6 race_White 0.009282 7 major_STEM 0.007789 8 work_industry_PE/VC 0.007667 9 major_Humanities 0.006021 10 work_industry_Nonprofit/Gov 0.005884 11 work_industry_Financial Services 0.004310 12 race_Hispanic 0.002785 13 work_industry_Investment Banking 0.002768 14 work_industry_Technology 0.001727 15 race_Other 0.001186 16 work_industry_Energy 0.000807 17 work_industry_Real Estate 0.000767 18 work_industry_Retail 0.000759 19 work_industry_Media/Entertainment 0.000040 20 work_industry_Health Care -0.000105 21 work_industry_Other -0.000904 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Removendo colunas prejudiciais\ndf = df.drop(columns= [\"work_industry_Investment Management\"])\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo apresentou aumento de precis\u00e3o em um ponto percentual, portanto ser\u00e1 realizado o 3\u00b0 retreino, seguindo a mesma l\u00f3gica, ou seja, removendo a vari\u00e1vel com menor valor no teste de <code>permutation_importance</code>, desde que esta seja negativa.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\", \"work_industry_Investment Management\" e \"work_industry_Other\"  para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.82 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.036893 1 gpa 0.020613 2 gender 0.012203 3 major_STEM 0.011768 4 race_Black 0.010856 5 race_White 0.008975 6 race_international 0.008967 7 major_Humanities 0.007684 8 work_industry_Nonprofit/Gov 0.005609 9 work_industry_Consulting 0.005165 10 work_industry_PE/VC 0.005157 11 work_industry_Technology 0.004673 12 work_industry_Financial Services 0.003422 13 race_Hispanic 0.002526 14 work_industry_Investment Banking 0.001727 15 work_industry_Real Estate 0.000960 16 work_industry_Energy 0.000823 17 race_Other 0.000299 18 work_industry_Retail -0.000032 19 work_industry_Media/Entertainment -0.000734 20 work_industry_Health Care -0.001598 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Removendo colunas prejudiciais\ndf = df.drop(columns= [\"work_industry_Investment Management\", \"work_industry_Other\"])\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo n\u00e3o apresentou varia\u00e7\u00e3o de precis\u00e3o, entretanto percebe-se um padr\u00e3o. Toda vez que o modelo \u00e9 retreinado alguma das vari\u00e1veis dummmies relacianadas a coluna \"work_industry\" s\u00e3o estimadas como prejudicias ao modelo, logo o 4\u00b0 retreino ser\u00e1 realizado sem a vari\u00e1vel \"work_industry\" por inteira.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\" e \"work_industry\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.79 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.011090 1 race_Hispanic 0.002510 2 race_Black 0.001606 3 gpa -0.000597 4 major_STEM -0.001872 5 race_Other -0.003228 6 race_White -0.003810 7 gender -0.004810 8 race_international -0.006053 9 major_Humanities -0.007764 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\", \"work_industry\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo apresentou queda de precis\u00e3o em tr\u00eas pontos percentuais, logo conclui-se que parte dos valores da coluna \"work_industry\" s\u00e3o relevantes, portanto o 5\u00b0 treino ser\u00e1 realizado apenas removendo vari\u00e1veis indicadas como prejudiciais.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\", \"work_industry_Investment Management\", \"work_industry_Other\", \"work_industry_Health Care\" e \"work_industry_Media/Entertainment\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.82 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.039290 1 gpa 0.021606 2 gender 0.014738 3 race_international 0.014237 4 race_Black 0.013043 5 major_Humanities 0.011872 6 major_STEM 0.011558 7 race_White 0.010856 8 work_industry_Consulting 0.006610 9 work_industry_Financial Services 0.005601 10 work_industry_PE/VC 0.004455 11 work_industry_Nonprofit/Gov 0.003697 12 race_Hispanic 0.002881 13 work_industry_Investment Banking 0.001251 14 race_Other 0.001227 15 work_industry_Real Estate 0.000920 16 work_industry_Technology 0.000081 17 work_industry_Retail 0.000000 18 work_industry_Energy -0.000040 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Removendo colunas prejudiciais\ndf = df.drop(columns= [\"work_industry_Investment Management\", \"work_industry_Other\", \"work_industry_Health Care\", \"work_industry_Media/Entertainment\"])\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo n\u00e3o apresentou varia\u00e7\u00e3o de precis\u00e3o, e o \u00fanico valor negativo presente nesta avalia\u00e7\u00e3o \u00e9 estatisticamente irrelevante, portanto a melhor precis\u00e3o que este modelo pode obter com estas condi\u00e7\u00f5es \u00e9 de 82%.</p>"},{"location":"knn/main/#analise","title":"An\u00e1lise","text":"<p>Em rela\u00e7\u00e3o ao modelo de \u00e1rvore de decis\u00e3o treinado anteriormente, este modelo requer maior cuidado com a limpeza e tratamento da base e \u00e9 mais sens\u00edvel \u00e1 outliers, entretanto obteve melhor resultado em suas predi\u00e7\u00f5es.</p>"},{"location":"randomForest/main/","title":"Random Forest","text":""},{"location":"randomForest/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de Random Tree.</p>"},{"location":"randomForest/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"randomForest/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-10-26T23:12:03.717054 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> 2025-10-26T23:12:03.796278 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-10-26T23:12:03.829240 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-10-26T23:12:03.866324 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual e n\u00e3o apresenta binariedade, a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-10-26T23:12:03.942065 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel. E como esta coluna n\u00e3o apresentar binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais e nulos em valores n\u00famericos. </p> 2025-10-26T23:12:03.983274 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-10-26T23:12:04.030240 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-10-26T23:12:04.119062 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-10-26T23:12:04.207625 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-10-26T23:12:04.316469 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"randomForest/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa major race gmat work_exp work_industry admission 1 3.12 0 1 660 7 1 Refused 0 3.38 2 1 610 8 1 Refused 1 3.12 2 3 580 5 1 Refused 1 3.38 1 4 660 5 1 Admit 0 3.19 1 1 680 5 9 Refused 1 3.1 2 1 630 5 9 Refused 1 3.4 1 5 770 5 13 Admit 1 3.37 1 3 700 4 13 Refused 0 3.18 0 4 670 5 9 Refused <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 993 Female False 3.27 STEM Black 650 3 PE/VC nan 2138 Male False 3.2 Humanities White 670 4 PE/VC nan 1186 Male False 3.2 Humanities Asian 640 4 Technology nan 5760 Female False 3.16 Business White 610 5 Nonprofit/Gov nan 3540 Male False 3.5 Humanities White 720 4 Technology nan 2272 Male False 3.27 STEM Black 630 6 Consulting nan 3028 Female False 3.32 Business Asian 620 5 Nonprofit/Gov nan 1689 Male True 3 Humanities nan 580 5 Consulting nan 4741 Female False 2.91 STEM Asian 570 5 Other nan"},{"location":"randomForest/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nlabel_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=27, stratify=y)\n</code></pre>"},{"location":"randomForest/main/#treinamento-da-arvore","title":"Treinamento da \u00c1rvore","text":"Modelo da \u00c1rvorecode <p>Accuracy: 0.8386 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 4 gmat 0.519098 1 gpa 0.322064 0 gender 0.064424 3 race 0.035490 6 work_industry 0.028160 5 work_exp 0.021203 2 major 0.009562 </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Initialize and train the model\nrf = RandomForestClassifier(n_estimators=100,  # Number of trees\n                            max_depth=5,       # Max depth of trees\n                            max_features='sqrt',  # Features per split\n                            random_state=42)\nrf.fit(X_train, y_train)\n\n# Predict and evaluate\npredictions = rf.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n\nfeature_importance = pd.DataFrame({\n    'Feature': rf.feature_names_in_,\n    'Import\u00e2ncia': rf.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre>"},{"location":"randomForest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Com este treinamento o modelo apresenta 78.48% de precis\u00e3o, n\u00famero satisfat\u00f3rio para um modelo de classifica\u00e7\u00e3o real, e as colunas mais importantes em sua tomada de deicis\u00e3o s\u00e3o as ponuta\u00e7\u00f5es gmat e gpa com 51.9% e 32.2% de import\u00e2ncia, respectivamente, e a coluna com menor relevancia para o modelo \u00e9 a major, com  0.9% de import\u00e2ncia.</p>"},{"location":"randomForest/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O processo de treinamento da Random Forest consistiu em preparar os dados (remo\u00e7\u00e3o de application_id, codifica\u00e7\u00f5es e alinhamento dos tipos), separar a base em 70% treino e 30% valida\u00e7\u00e3o com estratifica\u00e7\u00e3o pela coluna admission, e ent\u00e3o ajustar um comit\u00ea de \u00e1rvores de decis\u00e3o: cada \u00e1rvore foi treinada em bootstraps do conjunto de treino e, a cada divis\u00e3o, considerou apenas um subconjunto aleat\u00f3rio de vari\u00e1veis, o que reduz correla\u00e7\u00e3o entre \u00e1rvores e estabiliza o erro. A previs\u00e3o final resulta do voto majorit\u00e1rio entre as \u00e1rvores. A avalia\u00e7\u00e3o do modelo obteve 78,48% de acur\u00e1cia, e as import\u00e2ncias de atributos, calculadas pelo ganho m\u00e9dio de impureza ao longo das divis\u00f5es, indicaram GMAT (51,9%) e GPA (32,2%) como os preditores mais influentes, enquanto major apresentou baixa relev\u00e2ncia (0,9%).</p>"}]}