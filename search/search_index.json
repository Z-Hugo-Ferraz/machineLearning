{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"arvore/main/","title":"\u00c1rvore de Decis\u00e3o","text":""},{"location":"arvore/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de \u00e1rvore de decis\u00e3o.</p>"},{"location":"arvore/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"arvore/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-12-04T02:28:41.827685 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> 2025-12-04T02:28:41.914637 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-12-04T02:28:41.948305 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-12-04T02:28:41.987476 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual e n\u00e3o apresenta binariedade, a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-12-04T02:28:42.066038 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel. E como esta coluna n\u00e3o apresentar binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais e nulos em valores n\u00famericos. </p> 2025-12-04T02:28:42.107753 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-12-04T02:28:42.155776 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-12-04T02:28:42.250393 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-12-04T02:28:42.341047 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-12-04T02:28:42.451627 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"arvore/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa major race gmat work_exp work_industry admission 1 3.33 1 0 720 5 9 Admit 1 3.12 2 2 580 5 9 Refused 0 3.32 2 5 640 4 1 Refused 1 3 2 4 590 6 8 Refused 0 3.35 0 0 690 6 13 Admit 1 3.26 1 5 690 5 1 Admit 1 3.1 2 0 630 4 10 Refused 1 3.49 2 4 670 4 1 Waitlist 1 3.31 1 0 610 5 0 Refused <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 5365 Female True 3.41 Business nan 660 6 Consulting Admit 4112 Male False 2.87 Humanities White 580 6 Technology nan 1050 Female False 3.2 Business White 580 6 Investment Banking nan 2665 Male False 3.07 STEM White 600 5 Consulting nan 3949 Female False 3.5 Humanities Asian 720 5 Financial Services Admit 1944 Female False 3.32 STEM White 720 2 Media/Entertainment Admit 4875 Male True 3.03 STEM nan 620 7 Consulting nan 553 Female False 3.35 Humanities White 640 5 Investment Banking Waitlist 1080 Female False 3.06 Business Hispanic 730 5 Nonprofit/Gov nan"},{"location":"arvore/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nlabel_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=27, stratify=y)\n</code></pre>"},{"location":"arvore/main/#treinamento-da-arvore","title":"Treinamento da \u00c1rvore","text":"Modelo da \u00c1rvorecode <p>Precis\u00e3o da Valida\u00e7\u00e3o: 0.7784 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 1 gpa 0.284064 4 gmat 0.281837 6 work_industry 0.158193 5 work_exp 0.119838 2 major 0.069255 3 race 0.069199 0 gender 0.017615 2025-12-04T02:28:43.721498 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\ny_pred = classifier.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o da Valida\u00e7\u00e3o: {accuracy:.4f}\")\n\nfeature_importance = pd.DataFrame({\n    'Feature': classifier.feature_names_in_,\n    'Import\u00e2ncia': classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n\nplt.figure(figsize=(20, 10))\ntree.plot_tree(classifier, max_depth=5, fontsize=10)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"arvore/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Com este treinamento o modelo apresenta 78.48% de precis\u00e3o, n\u00famero satisfat\u00f3rio para um modelo de classifica\u00e7\u00e3o real, e as colunas mais importantes em sua tomada de deicis\u00e3o s\u00e3o as ponuta\u00e7\u00f5es gpa e gmat com 29.4% e 27.7% de import\u00e2ncia, respectivamente, e a coluna com menor relevancia para o modelo \u00e9 a gender, com  1.7% de import\u00e2ncia.</p> <p>Entretando utilizar mais dados no treinamento do modelo poderia melhorara sua precis\u00e3o. Logo, para compravar esta hip\u00f3tese o modelo ser\u00e1 treinado novamente com 80% da base de dados original para treinamento.</p>"},{"location":"arvore/main/#retreinamento","title":"Retreinamento","text":"Modelo da \u00c1rvorecode <p>Precis\u00e3o da Valida\u00e7\u00e3o: 0.7764 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 1 gpa 0.335151 4 gmat 0.294273 6 work_industry 0.128850 3 race 0.089507 5 work_exp 0.083052 2 major 0.052624 0 gender 0.016543 2025-12-04T02:28:44.556834 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\ny_pred = classifier.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o da Valida\u00e7\u00e3o: {accuracy:.4f}\")\n\nfeature_importance = pd.DataFrame({\n    'Feature': classifier.feature_names_in_,\n    'Import\u00e2ncia': classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n\nplt.figure(figsize=(20, 10))\ntree.plot_tree(classifier, max_depth=5, fontsize=10)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"arvore/main/#avaliacao-do-novo-modelo","title":"Avalia\u00e7\u00e3o do novo modelo","text":"<p>Com este retreinamento a hip\u00f3tese anterior \u00e9 rejeitada, pois ao utilizar 80% da base para treinamento a precis\u00e3o geral do modelo caiu para 77.89%. Entretanto, as m\u00e9tricas de gpa e gmat continuaram sendo as mais relevantes, comprovando sua import\u00e2ncia para o modelo.</p>"},{"location":"arvore/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Ao fim deste roteiro nota-se que as colunas n\u00e3o precisam estar normalizadas para que se treine uma \u00e1rvore de decis\u00e3o, aumentar os dados de treinamento do modelo, em detrimento dos dados de teste, pode prejudicar a precis\u00e3o geral do mesmo e que grande parte do tempo de trabalho do cientista de dados \u00e9 a an\u00e1lise e limpeza da base de dados original.  </p>"},{"location":"kmeans/main/","title":"K-Means","text":""},{"location":"kmeans/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de K-Means.</p>"},{"location":"kmeans/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"kmeans/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-12-04T02:28:45.299441 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> 2025-12-04T02:28:45.381587 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-12-04T02:28:45.412558 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-12-04T02:28:45.449972 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual, n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 2 vari\u00e1veis dummies.</p> 2025-12-04T02:28:45.528536 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel, e gerar dummies para cada valor registrado na coluna, pois esta n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"). </p> 2025-12-04T02:28:45.569958 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-12-04T02:28:45.619144 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-12-04T02:28:45.710227 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 13 vari\u00e1veis dummies.</p> 2025-12-04T02:28:45.807966 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-12-04T02:28:45.917947 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"kmeans/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa gmat work_exp admission race_Black race_Hispanic race_Other race_White race_international major_Humanities major_STEM work_industry_Consulting work_industry_Energy work_industry_Financial Services work_industry_Health Care work_industry_Investment Banking work_industry_Investment Management work_industry_Media/Entertainment work_industry_Nonprofit/Gov work_industry_Other work_industry_PE/VC work_industry_Real Estate work_industry_Retail work_industry_Technology 1 0.523243 -0.225052 -0.0164207 Refused False True False False False False True False False False False False False False False False True False False False 1 -1.12661 0.586457 0.952244 Refused False False False True False True False False False False False False False False False True False False False False 1 1.31517 2.0066 -0.985085 Refused False True False False False False True True False False False False False False False False False False False False 1 -0.268685 0.180703 0.952244 Refused False False False True False False True False False False False True False False False False False False False False 0 0.721225 0.586457 0.952244 Refused True False False False False False True False False False False False False False False False True False False False 1 -0.268685 -0.427929 -0.985085 Refused False False False False False False False True False False False False False False False False False False False False 1 -0.598655 -0.225052 -0.0164207 Refused False False False False True False False False False False False False False False False False False False False True 0 0.457249 1.39797 -0.0164207 Refused False False False False True True False False False False False False False False False False True False False False 0 0.655231 -0.427929 -0.985085 Refused False False False False False False False False False False False False False False False False False False False True <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 5868 Male False 3.46 Business Other 730 4 PE/VC Admit 1243 Male True 3.22 STEM nan 620 5 PE/VC nan 3619 Male False 3.34 Business Other 650 5 Other nan 5335 Male False 3.3 Business Asian 600 6 Consulting nan 1920 Female False 3.55 STEM White 680 5 Consulting nan 3448 Female False 3.05 Humanities Black 570 6 Nonprofit/Gov nan 5932 Male False 3.26 Humanities Asian 670 3 CPG Admit 1160 Female True 2.97 Business nan 600 2 Consulting nan 5793 Male False 3.11 Humanities White 580 5 Technology nan"},{"location":"kmeans/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n</code></pre>"},{"location":"kmeans/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"Treinamentocode <pre><code>import base64\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Carregar os dados\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n# Excluir as colunas n\u00e3o desejadas\ndf = df.drop(columns=[\"application_id\", \"international\"])\n\n# Preencher valores nulos\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n# Label encoding da coluna em texto bin\u00e1ria\nlabel_encoder = LabelEncoder()\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n# Escalonar vari\u00e1veis cont\u00ednuas\nscaler = StandardScaler()\ndf[[\"gpa\", \"gmat\", \"work_exp\"]] = scaler.fit_transform(df[[\"gpa\", \"gmat\", \"work_exp\"]])\n\n# Gerar dummies\ndf = pd.get_dummies(df, columns=[\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n# Separar vari\u00e1veis independentes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reduzir para 2 dimens\u00f5es com PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_train)\n\n# Treinar KMeans\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Plot\nplt.figure(figsize=(12, 10))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"viridis\", s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c=\"red\", marker=\"*\", s=200, label=\"Centroids\")\nplt.title(\"K-Means Clustering Results (PCA 2D)\")\nplt.xlabel(\"PCA Feature 1\")\nplt.ylabel(\"PCA Feature 2\")\nplt.legend()\n\n# Salvar em buffer png\nbuffer = BytesIO()\nplt.savefig(buffer, format=\"png\", transparent=True, bbox_inches=\"tight\")\nbuffer.seek(0)\n\n# Converter em base64\nimg_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n\n# Criar tag HTML para embutir no MkDocs\nhtml_img = f'&lt;img src=\"data:image/png;base64,{img_base64}\" alt=\"KMeans clustering\" /&gt;'\n\nprint(html_img)\n</code></pre>"},{"location":"kmeans/main/#avaliacao","title":"Avalia\u00e7\u00e3o","text":"Treinamentocode <p>Acur\u00e1cia: 84.14% Matriz de Confus\u00e3o:</p> Classe Pred 0 Classe Pred 1 Classe Pred 2 Classe Real 0 0 704 0 Classe Real 1 0 4169 0 Classe Real 2 0 82 0 <pre><code>import pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\nfrom scipy.stats import mode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Carregar os dados\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n# Excluir as colunas n\u00e3o desejadas\ndf = df.drop(columns=[\"application_id\", \"international\"])\n\n# Preencher valores nulos\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n# Label encoding da coluna em texto bin\u00e1ria\nlabel_encoder = LabelEncoder()\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n# Escalonar vari\u00e1veis cont\u00ednuas\nscaler = StandardScaler()\ndf[[\"gpa\", \"gmat\", \"work_exp\"]] = scaler.fit_transform(df[[\"gpa\", \"gmat\", \"work_exp\"]])\n\n# Gerar dummies\ndf = pd.get_dummies(df, columns=[\"race\", \"major\", \"work_industry\"], drop_first=True)\n\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reduzir para 2 dimens\u00f5es com PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_train)\n\n# Treinar KMeans\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Mapear clusters para classes reais por voto majorit\u00e1rio\ncluster_map = {}\nfor c in np.unique(labels):\n    mask = labels == c\n    majority_class = mode(y_train[mask], keepdims=False)[0]\n    cluster_map[c] = majority_class\n\n# Reatribuir clusters como classes previstas\ny_pred = np.array([cluster_map[c] for c in labels])\n\n# Calcular acur\u00e1cia e matriz de confus\u00e3o\nacc = accuracy_score(y_train, y_pred)\ncm = confusion_matrix(y_train, y_pred)\n\ncm_df = pd.DataFrame(\n    cm,\n    index=[f\"Classe Real {cls}\" for cls in np.unique(y_train)],\n    columns=[f\"Classe Pred {cls}\" for cls in np.unique(y_train)]\n)\n\nprint(f\"Acur\u00e1cia: {acc*100:.2f}%\")\nprint(\"&lt;br&gt;Matriz de Confus\u00e3o:\")\nprint(cm_df.to_html())\n</code></pre>"},{"location":"kmeans/main/#analise","title":"An\u00e1lise","text":"<p>Apesar de atingir 84,14% de acur\u00e1cia, o modelo aparenta ser inadequado para a base, pois, ainda que tenha encontrado 3 clusters, estes n\u00e3o correspondem as classifica\u00e7\u00f5es desejadas, de maneira que, para todos os clusters, a maioria dos pontos possuem o r\u00f3tulo de <code>Refused</code>, fazendo com que todas as predi\u00e7\u00f5es sejam classificadas como <code>Refused</code>.</p>"},{"location":"knn/main/","title":"KNN","text":""},{"location":"knn/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de K-Nearest Neighbors (KNN).</p>"},{"location":"knn/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"knn/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-12-04T02:28:46.610266 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> 2025-12-04T02:28:46.689759 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel bin\u00e1ria num\u00e9rica para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-12-04T02:28:46.721605 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-12-04T02:28:46.759206 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual, n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 2 vari\u00e1veis dummies.</p> 2025-12-04T02:28:46.835490 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel, e gerar dummies para cada valor registrado na coluna, pois esta n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"). </p> 2025-12-04T02:28:46.875864 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-12-04T02:28:46.923833 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores serem num\u00e9ricos e a maioria das vari\u00e1veis do modelo serem bin\u00e1rias ou dummies, esta deve ser padronizada para valores entre 0 e 1.</p> 2025-12-04T02:28:47.103490 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade e n\u00e3o possui no\u00e7\u00e3o de escala (como em \"ruim\", \"regular\" e \"bom\"), a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o \"One Hot\", transformando-a em 13 vari\u00e1veis dummies.</p> 2025-12-04T02:28:47.194125 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-12-04T02:28:47.305339 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"knn/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa gmat work_exp admission race_Black race_Hispanic race_Other race_White race_international major_Humanities major_STEM work_industry_Consulting work_industry_Energy work_industry_Financial Services work_industry_Health Care work_industry_Investment Banking work_industry_Investment Management work_industry_Media/Entertainment work_industry_Nonprofit/Gov work_industry_Other work_industry_PE/VC work_industry_Real Estate work_industry_Retail work_industry_Technology 1 1.44716 0.180703 1.92091 Refused False False False True False False True False False False False False False False False False True False False False 1 -0.928626 -1.03656 0.952244 Refused False False False False True False True False False False False False False False False False False True False False 1 -0.268685 0.992212 0.952244 Waitlist False False False False False True False True False False False False False False False False False False False False 0 1.97511 -0.427929 -0.0164207 Refused True False False False False True False False False False False False False False False False True False False False 1 0.787219 0.789334 -0.0164207 Admit False False False True False False True True False False False False False False False False False False False False 1 -2.18251 -0.630806 -1.95375 Refused False True False False False True False False False False False False True False False False False False False False 1 -0.400673 -0.0221743 0.952244 Refused True False False False False False True False False False False False False False False False True False False False 1 -1.52257 -0.833683 -0.0164207 Refused True False False False False True False False False False False False False False False False True False False False 1 -1.52257 -1.64519 1.92091 Refused False False False False True True False False False False False False False False False False False False False True <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 1037 Male True 2.97 STEM nan 570 4 Nonprofit/Gov nan 4845 Female True 3.24 Business nan 600 5 Consulting nan 6025 Male True 3.15 Business nan 570 5 Investment Banking nan 2108 Male False 3.31 STEM White 680 7 Technology Admit 1553 Male True 3.25 STEM nan 670 8 Financial Services nan 3105 Male False 3.53 Business Black 620 4 CPG nan 344 Female False 3.18 STEM White 590 6 Nonprofit/Gov Admit 3974 Male True 3.4 Humanities nan 770 5 Technology Admit 3758 Male True 3.43 Humanities nan 690 6 Consulting nan"},{"location":"knn/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nplt.figure(figsize=(12, 10))\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n</code></pre>"},{"location":"knn/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>A seguir, foi feito o treinamento do modelo utilizando os tr\u00eas vizinhos mais pr\u00f3ximos para a classifica\u00e7\u00e3o, ou seja <code>k = 4</code>, e foi utilizada a fun\u00e7\u00e3o <code>permutation_importance</code> para avaliar a import\u00e2ncia das features no modelo.</p> <p>Esta fun\u00e7\u00e3o realiza diversas itera\u00e7\u00f5es sequ\u00eanciais com a base de teste. Em cada uma das itera\u00e7\u00f5es, uma coluna da base de teste tem seus valores embaralhados, e o modelo tenta classifica-l\u00e1. Com as classifica\u00e7\u00f5es obtidas, esta fun\u00e7\u00e3o calcula a diferen\u00e7a na precis\u00e3o. Desta forma medindo a import\u00e2ncia de cada feature.</p> Modelocode <p>Accuracy: 0.79 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.013785 1 work_industry_Health Care 0.003349 2 race_international 0.003253 3 work_industry_Technology 0.000993 4 work_industry_Real Estate 0.000694 5 work_industry_Nonprofit/Gov 0.000557 6 work_industry_Media/Entertainment -0.000065 7 work_industry_Retail -0.000137 8 work_industry_Investment Banking -0.000202 9 work_industry_Investment Management -0.000557 10 gender -0.000597 11 work_industry_PE/VC -0.000718 12 work_industry_Energy -0.000799 13 major_Humanities -0.000856 14 race_Other -0.000944 15 race_Black -0.001001 16 race_Hispanic -0.001316 17 work_industry_Financial Services -0.001937 18 work_industry_Other -0.002171 19 major_STEM -0.002373 20 race_White -0.003890 21 gpa -0.005093 22 work_industry_Consulting -0.009023 23 work_exp -0.011913 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\ndf[\"work_exp\"] = scaler.fit_transform(df[[\"work_exp\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre>"},{"location":"knn/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Ao fim do treinamento o modelo apresentou 79% de precis\u00e3o, valor satisfat\u00f3rio. Entretanto algumas features apresentaram valores negativos no teste de <code>permutation_importance</code>, o que indica que o modelo ficaria mais preciso caso esta vari\u00e1vel n\u00e3o estivesse presente, por\u00e9m por se tratar de um valor muito pr\u00f3ximo a zero, este indicio pode ser apenas ru\u00eddo estat\u00edstico.</p>"},{"location":"knn/main/#retreinamento","title":"Retreinamento","text":"1\u00b0 retreino2\u00b0 retreino3\u00b0 retreino4\u00b0 retreino5\u00b0 retreino <p>A seguir foi feito o retreinamento do modelo sem a coluna \"work_exp\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.81 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.030517 1 gpa 0.012873 2 gender 0.009201 3 race_international 0.008805 4 race_Black 0.008394 5 major_STEM 0.007199 6 race_White 0.005634 7 work_industry_Consulting 0.004487 8 work_industry_PE/VC 0.004431 9 work_industry_Financial Services 0.003979 10 work_industry_Nonprofit/Gov 0.003277 11 race_Hispanic 0.003107 12 major_Humanities 0.002994 13 work_industry_Technology 0.002405 14 work_industry_Other 0.001953 15 work_industry_Energy 0.001574 16 work_industry_Real Estate 0.001533 17 work_industry_Investment Banking 0.001251 18 race_Other 0.001017 19 work_industry_Media/Entertainment 0.000831 20 work_industry_Retail -0.000032 21 work_industry_Health Care -0.001768 22 work_industry_Investment Management -0.002147 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo apresentou aumento de precis\u00e3o em dois pontos percentuais, portanto ser\u00e1 realizado o 2\u00b0 retreino, seguindo a mesma l\u00f3gica, ou seja, removendo a vari\u00e1vel com menor valor no teste de <code>permutation_importance</code>, desde que esta seja negativa.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\" e \"work_industry_Investment Management\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.82 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.036449 1 gpa 0.019580 2 race_Black 0.010807 3 work_industry_Consulting 0.010500 4 race_international 0.010291 5 gender 0.009968 6 race_White 0.009282 7 major_STEM 0.007789 8 work_industry_PE/VC 0.007667 9 major_Humanities 0.006021 10 work_industry_Nonprofit/Gov 0.005884 11 work_industry_Financial Services 0.004310 12 race_Hispanic 0.002785 13 work_industry_Investment Banking 0.002768 14 work_industry_Technology 0.001727 15 race_Other 0.001186 16 work_industry_Energy 0.000807 17 work_industry_Real Estate 0.000767 18 work_industry_Retail 0.000759 19 work_industry_Media/Entertainment 0.000040 20 work_industry_Health Care -0.000105 21 work_industry_Other -0.000904 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Removendo colunas prejudiciais\ndf = df.drop(columns= [\"work_industry_Investment Management\"])\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo apresentou aumento de precis\u00e3o em um ponto percentual, portanto ser\u00e1 realizado o 3\u00b0 retreino, seguindo a mesma l\u00f3gica, ou seja, removendo a vari\u00e1vel com menor valor no teste de <code>permutation_importance</code>, desde que esta seja negativa.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\", \"work_industry_Investment Management\" e \"work_industry_Other\"  para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.82 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.036893 1 gpa 0.020613 2 gender 0.012203 3 major_STEM 0.011768 4 race_Black 0.010856 5 race_White 0.008975 6 race_international 0.008967 7 major_Humanities 0.007684 8 work_industry_Nonprofit/Gov 0.005609 9 work_industry_Consulting 0.005165 10 work_industry_PE/VC 0.005157 11 work_industry_Technology 0.004673 12 work_industry_Financial Services 0.003422 13 race_Hispanic 0.002526 14 work_industry_Investment Banking 0.001727 15 work_industry_Real Estate 0.000960 16 work_industry_Energy 0.000823 17 race_Other 0.000299 18 work_industry_Retail -0.000032 19 work_industry_Media/Entertainment -0.000734 20 work_industry_Health Care -0.001598 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Removendo colunas prejudiciais\ndf = df.drop(columns= [\"work_industry_Investment Management\", \"work_industry_Other\"])\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo n\u00e3o apresentou varia\u00e7\u00e3o de precis\u00e3o, entretanto percebe-se um padr\u00e3o. Toda vez que o modelo \u00e9 retreinado alguma das vari\u00e1veis dummmies relacianadas a coluna \"work_industry\" s\u00e3o estimadas como prejudicias ao modelo, logo o 4\u00b0 retreino ser\u00e1 realizado sem a vari\u00e1vel \"work_industry\" por inteira.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\" e \"work_industry\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.79 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.011090 1 race_Hispanic 0.002510 2 race_Black 0.001606 3 gpa -0.000597 4 major_STEM -0.001872 5 race_Other -0.003228 6 race_White -0.003810 7 gender -0.004810 8 race_international -0.006053 9 major_Humanities -0.007764 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\", \"work_industry\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\"], drop_first=True)\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo apresentou queda de precis\u00e3o em tr\u00eas pontos percentuais, logo conclui-se que parte dos valores da coluna \"work_industry\" s\u00e3o relevantes, portanto o 5\u00b0 treino ser\u00e1 realizado apenas removendo vari\u00e1veis indicadas como prejudiciais.</p> <p>A seguir foi feito o retreinamento do modelo sem as colunas \"work_exp\", \"work_industry_Investment Management\", \"work_industry_Other\", \"work_industry_Health Care\" e \"work_industry_Media/Entertainment\" para testar a hip\u00f3tese de que o modelo teria melhora em sua remo\u00e7\u00e3o.</p> Modelocode <p>Accuracy: 0.82 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 0 gmat 0.039290 1 gpa 0.021606 2 gender 0.014738 3 race_international 0.014237 4 race_Black 0.013043 5 major_Humanities 0.011872 6 major_STEM 0.011558 7 race_White 0.010856 8 work_industry_Consulting 0.006610 9 work_industry_Financial Services 0.005601 10 work_industry_PE/VC 0.004455 11 work_industry_Nonprofit/Gov 0.003697 12 race_Hispanic 0.002881 13 work_industry_Investment Banking 0.001251 14 race_Other 0.001227 15 work_industry_Real Estate 0.000920 16 work_industry_Technology 0.000081 17 work_industry_Retail 0.000000 18 work_industry_Energy -0.000040 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\nlabel_encoder = LabelEncoder()\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\" , \"work_exp\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding da coluna em texto bin\u00e1ria\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\n\n#Escolonando as v\u00e1riaveis continuas\ndf[\"gpa\"] = scaler.fit_transform(df[[\"gpa\"]])\ndf[\"gmat\"] = scaler.fit_transform(df[[\"gmat\"]])\n\n#Gerando dummies das colunas em texto n\u00e3o bin\u00e1rias\ndf = pd.get_dummies(df,columns= [\"race\", \"major\", \"work_industry\"], drop_first=True)\n\n#Removendo colunas prejudiciais\ndf = df.drop(columns= [\"work_industry_Investment Management\", \"work_industry_Other\", \"work_industry_Health Care\", \"work_industry_Media/Entertainment\"])\n\n#Separar em vairaveis indenpendetes e dependente\nX = df.drop(\"admission\", axis=1)\ny = label_encoder.fit_transform(df[\"admission\"])\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Calcular permutation importance\nresult = permutation_importance(\n    knn, X_test, y_test,\n    n_repeats=100,        # n\u00famero de permuta\u00e7\u00f5es (quanto mais, mais est\u00e1vel)\n    random_state=42\n)\n\n# Ordenar import\u00e2ncias\nimportances = result.importances_mean\nindices = np.argsort(importances)[::-1]  # do mais importante ao menos\n\ndf_result = pd.DataFrame({\n    \"Feature\": X.columns[indices],\n    \"Import\u00e2ncia\": importances[indices]\n})\n\n# Gerar o markdown da tabela\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(df_result.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre> <ul> <li>An\u00e1lise</li> </ul> <p>Ap\u00f3s o retreinamento, o modelo n\u00e3o apresentou varia\u00e7\u00e3o de precis\u00e3o, e o \u00fanico valor negativo presente nesta avalia\u00e7\u00e3o \u00e9 estatisticamente irrelevante, portanto a melhor precis\u00e3o que este modelo pode obter com estas condi\u00e7\u00f5es \u00e9 de 82%.</p>"},{"location":"knn/main/#analise","title":"An\u00e1lise","text":"<p>Em rela\u00e7\u00e3o ao modelo de \u00e1rvore de decis\u00e3o treinado anteriormente, este modelo requer maior cuidado com a limpeza e tratamento da base e \u00e9 mais sens\u00edvel \u00e1 outliers, entretanto obteve melhor resultado em suas predi\u00e7\u00f5es.</p>"},{"location":"pageRank/main/","title":"Page Rank","text":""},{"location":"pageRank/main/#pagerank","title":"PageRank","text":""},{"location":"pageRank/main/#1-introducao","title":"1. Introdu\u00e7\u00e3o","text":"<p>O dataset roadNet-CA representa a malha vi\u00e1ria da Calif\u00f3rnia, onde:</p> <ul> <li>N\u00f3s = interse\u00e7\u00f5es  </li> <li>Arestas = segmentos vi\u00e1rios direcionados  </li> </ul>"},{"location":"pageRank/main/#2-carregamento-do-grafo","title":"2. Carregamento do Grafo","text":"Resultadocode <p>N\u00famero de n\u00f3s: 1965206</p> <p>N\u00famero de arestas: 5533214</p> <p>\u00c9 direcionado? True</p> <pre><code>import networkx as nx\n\npath = \"./docs/pageRank/roadNet-CA.txt\"\n\nG = nx.read_edgelist(\n    path,\n    comments=\"#\",\n    nodetype=int,\n    create_using=nx.DiGraph()\n)\n\nprint(f\"\\nN\u00famero de n\u00f3s: {G.number_of_nodes()}\")\nprint(f\"\\nN\u00famero de arestas: {G.number_of_edges()}\")\nprint(f\"\\n\u00c9 direcionado? {G.is_directed()}\")\n</code></pre>"},{"location":"pageRank/main/#3-implementacao-do-pagerank-manual","title":"3. Implementa\u00e7\u00e3o do PageRank Manual","text":"<p>A f\u00f3rmula utilizada:</p> \\[ PR(p_i) = \\frac{1-d}{N} + d \\sum_{p_j \\in M(p_i)} \\frac{PR(p_j)}{L(p_j)} \\] <pre><code>def pagerank_custom(G, d=0.85, tol=1e-4, max_iter=100):\n    nodes = list(G.nodes())\n    N = len(nodes)\n    idx = {n: i for i, n in enumerate(nodes)}\n\n    pr = np.full(N, 1 / N)\n    out_deg = np.array([G.out_degree(n) for n in nodes])\n\n    predecessors = {i: [idx[p] for p in G.predecessors(nodes[i])]\n                    for i in range(N)}\n\n    base = (1 - d) / N\n\n    for _ in range(max_iter):\n        pr_new = np.full(N, base)\n\n        dangling_sum = pr[out_deg == 0].sum()\n        pr_new += d * dangling_sum / N\n\n        for i in range(N):\n            s = 0\n            for j in predecessors[i]:\n                if out_deg[j] &gt; 0:\n                    s += pr[j] / out_deg[j]\n            pr_new[i] += d * s\n\n        if np.max(np.abs(pr_new - pr)) &lt; tol:\n            break\n\n        pr = pr_new\n\n    return {nodes[i]: float(pr[i]) for i in range(N)}\n</code></pre>"},{"location":"pageRank/main/#4-execucao-do-pagerank-com-d-085","title":"4. Execu\u00e7\u00e3o do PageRank com d = 0.85","text":"Resultadocode <p>========== RESULTADOS ==========</p> <p>Soma dos PR: 1.000000</p> <p>PR m\u00ednimo:  1.303935e-07</p> <p>PR m\u00e1ximo:  2.455213e-06</p> <p>Top-10 n\u00f3s por PageRank:</p> <ol> <li> <p>n\u00f3=225438 | PR=2.455213e-06</p> </li> <li> <p>n\u00f3=287362 | PR=2.383126e-06</p> </li> <li> <p>n\u00f3=241926 | PR=2.166864e-06</p> </li> <li> <p>n\u00f3=748883 | PR=2.022689e-06</p> </li> <li> <p>n\u00f3=1682326 | PR=2.022689e-06</p> </li> <li> <p>n\u00f3=241299 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=264566 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=403664 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=673507 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=1258079 | PR=1.950601e-06</p> </li> </ol> <pre><code>import numpy as np\nimport networkx as nx   \n\ndef pagerank_custom(G, d=0.85, tol=1e-4, max_iter=100):\n    nodes = list(G.nodes())\n    N = len(nodes)\n    idx = {n: i for i, n in enumerate(nodes)}\n\n    pr = np.full(N, 1.0 / N)\n    out_deg = np.array([G.out_degree(n) for n in nodes])\n    predecessors = {i: [idx[p] for p in G.predecessors(nodes[i])] for i in range(N)}\n\n    base = (1 - d) / N\n\n    for _ in range(max_iter):\n        pr_new = np.full(N, base)\n        dangling_sum = pr[out_deg == 0].sum()\n        pr_new += d * dangling_sum / N\n\n        for i in range(N):\n            s = 0.0\n            for j in predecessors[i]:\n                if out_deg[j] &gt; 0:\n                    s += pr[j] / out_deg[j]\n            pr_new[i] += d * s\n\n        if np.max(np.abs(pr_new - pr)) &lt; tol:\n            pr = pr_new\n            break\n\n        pr = pr_new\n\n    pr_dict = {nodes[i]: float(pr[i]) for i in range(N)}\n    return pr_dict\n\n\npath = \"./docs/pageRank/roadNet-CA.txt\"\n\nG = nx.read_edgelist(\n    path,\n    comments=\"#\",\n    nodetype=int,\n    create_using=nx.DiGraph()\n)\n\npr_dict = pagerank_custom(G, d=0.85)\n\npr_values = np.fromiter(pr_dict.values(), dtype=np.float64)\n\nprint(\"\\n========== RESULTADOS ==========\")\nprint(f\"\\nSoma dos PR: {pr_values.sum():.6f}\")\nprint(f\"\\nPR m\u00ednimo:  {pr_values.min():.6e}\")\nprint(f\"\\nPR m\u00e1ximo:  {pr_values.max():.6e}\")\n\nprint(\"\\nTop-10 n\u00f3s por PageRank:\")\ntop10 = sorted(pr_dict.items(), key=lambda x: x[1], reverse=True)[:10]\nfor i, (node, score) in enumerate(top10, 1):\n    print(f\"\\n{i:2d}. n\u00f3={node} | PR={score:.6e}\")\n</code></pre>"},{"location":"pageRank/main/#5-comparacao-com-networkx","title":"5. Compara\u00e7\u00e3o com NetworkX","text":"Resultadocode <p>========== RESULTADOS (NetworkX) ==========</p> <p>Soma dos PR: 1.000000</p> <p>PR m\u00ednimo:  1.303935e-07</p> <p>PR m\u00e1ximo:  2.455213e-06</p> <p>Top-10 n\u00f3s por PageRank:</p> <ol> <li> <p>n\u00f3=225438 | PR=2.455213e-06</p> </li> <li> <p>n\u00f3=287362 | PR=2.383126e-06</p> </li> <li> <p>n\u00f3=241926 | PR=2.166864e-06</p> </li> <li> <p>n\u00f3=748883 | PR=2.022689e-06</p> </li> <li> <p>n\u00f3=1682326 | PR=2.022689e-06</p> </li> <li> <p>n\u00f3=241299 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=264566 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=403664 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=673507 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=1258079 | PR=1.950601e-06</p> </li> </ol> <pre><code>import numpy as np\nimport networkx as nx\n\n\npath = \"./docs/pageRank/roadNet-CA.txt\"\n\n# Carregar grafo\nG = nx.read_edgelist(\n    path,\n    comments=\"#\",\n    nodetype=int,\n    create_using=nx.DiGraph()\n)\n\n# PageRank com networkx\npr_dict = nx.pagerank(G, alpha=0.85)\n\npr_values = np.fromiter(pr_dict.values(), dtype=float)\n\nprint(\"\\n========== RESULTADOS (NetworkX) ==========\")\nprint(f\"\\nSoma dos PR: {pr_values.sum():.6f}\")\nprint(f\"\\nPR m\u00ednimo:  {pr_values.min():.6e}\")\nprint(f\"\\nPR m\u00e1ximo:  {pr_values.max():.6e}\")\n\nprint(\"\\nTop-10 n\u00f3s por PageRank:\")\ntop10 = sorted(pr_dict.items(), key=lambda x: x[1], reverse=True)[:10]\nfor i, (node, score) in enumerate(top10, 1):\n    print(f\"\\n{i:2d}. n\u00f3={node} | PR={score:.6e}\")\n</code></pre> <p>A compara\u00e7\u00e3o entre os resultados obtidos pela implementa\u00e7\u00e3o manual do algoritmo PageRank e aqueles gerados pela fun\u00e7\u00e3o pagerank do NetworkX demonstra que n\u00e3o houve diferen\u00e7as significativas entre as duas abordagens. Tanto a soma total dos valores de PageRank quanto os valores m\u00ednimo e m\u00e1ximo coincidem exatamente nas duas execu\u00e7\u00f5es, indicando que o c\u00e1lculo converge para a mesma distribui\u00e7\u00e3o de import\u00e2ncia dos n\u00f3s. Al\u00e9m disso, o Top-10 n\u00f3s mais bem ranqueados \u00e9 id\u00eantico em ambas as metodologias, com os mesmos valores num\u00e9ricos de PageRank e na mesma ordem, o que confirma a correta implementa\u00e7\u00e3o da f\u00f3rmula iterativa utilizada. Esses resultados validam plenamente a implementa\u00e7\u00e3o manual, mostrando que ela est\u00e1 alinhada com o comportamento esperado de uma biblioteca consolidada como o NetworkX.</p>"},{"location":"pageRank/main/#6-top-10-nos-mais-importantes","title":"6. Top-10 N\u00f3s Mais Importantes","text":""},{"location":"pageRank/main/#7-variacao-do-fator-de-amortecimento","title":"7. Varia\u00e7\u00e3o do Fator de Amortecimento","text":"Resultadocode <p>==================== RESULTADOS PARA d = 0.5 ====================</p> <p>Soma dos PR: 1.000000</p> <p>PR m\u00ednimo:  2.862295e-07</p> <p>PR m\u00e1ximo:  1.653771e-06</p> <p>Top-10 n\u00f3s por PageRank:</p> <ol> <li> <p>n\u00f3=225438 | PR=1.653771e-06</p> </li> <li> <p>n\u00f3=287362 | PR=1.611366e-06</p> </li> <li> <p>n\u00f3=241926 | PR=1.484153e-06</p> </li> <li> <p>n\u00f3=748883 | PR=1.399344e-06</p> </li> <li> <p>n\u00f3=1682326 | PR=1.399344e-06</p> </li> <li> <p>n\u00f3=241299 | PR=1.356940e-06</p> </li> <li> <p>n\u00f3=264566 | PR=1.356940e-06</p> </li> <li> <p>n\u00f3=403664 | PR=1.356940e-06</p> </li> <li> <p>n\u00f3=673507 | PR=1.356940e-06</p> </li> <li> <p>n\u00f3=1258079 | PR=1.356940e-06</p> </li> </ol> <p>==================== RESULTADOS PARA d = 0.85 ====================</p> <p>Soma dos PR: 1.000000</p> <p>PR m\u00ednimo:  1.303935e-07</p> <p>PR m\u00e1ximo:  2.455213e-06</p> <p>Top-10 n\u00f3s por PageRank:</p> <ol> <li> <p>n\u00f3=225438 | PR=2.455213e-06</p> </li> <li> <p>n\u00f3=287362 | PR=2.383126e-06</p> </li> <li> <p>n\u00f3=241926 | PR=2.166864e-06</p> </li> <li> <p>n\u00f3=748883 | PR=2.022689e-06</p> </li> <li> <p>n\u00f3=1682326 | PR=2.022689e-06</p> </li> <li> <p>n\u00f3=241299 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=264566 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=403664 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=673507 | PR=1.950601e-06</p> </li> <li> <p>n\u00f3=1258079 | PR=1.950601e-06</p> </li> </ol> <p>==================== RESULTADOS PARA d = 0.99 ====================</p> <p>Soma dos PR: 1.000000</p> <p>PR m\u00ednimo:  6.805902e-08</p> <p>PR m\u00e1ximo:  2.775790e-06</p> <p>Top-10 n\u00f3s por PageRank:</p> <ol> <li> <p>n\u00f3=225438 | PR=2.775790e-06</p> </li> <li> <p>n\u00f3=287362 | PR=2.691830e-06</p> </li> <li> <p>n\u00f3=241926 | PR=2.439948e-06</p> </li> <li> <p>n\u00f3=748883 | PR=2.272026e-06</p> </li> <li> <p>n\u00f3=1682326 | PR=2.272026e-06</p> </li> <li> <p>n\u00f3=241299 | PR=2.188066e-06</p> </li> <li> <p>n\u00f3=264566 | PR=2.188066e-06</p> </li> <li> <p>n\u00f3=403664 | PR=2.188066e-06</p> </li> <li> <p>n\u00f3=673507 | PR=2.188066e-06</p> </li> <li> <p>n\u00f3=1258079 | PR=2.188066e-06</p> </li> </ol> <pre><code>import numpy as np\nimport networkx as nx\n\n\ndef pagerank_custom(G, d=0.85, tol=1e-4, max_iter=100):\n    # lista de n\u00f3s e mapeamentos\n    nodes = list(G.nodes())\n    N = len(nodes)\n    if N == 0:\n        return {}\n\n    idx = {n: i for i, n in enumerate(nodes)}\n\n    # vetor inicial uniforme\n    pr = np.full(N, 1.0 / N, dtype=float)\n\n    # grau de sa\u00edda de cada n\u00f3\n    out_deg = np.array([G.out_degree(n) for n in nodes], dtype=float)\n\n    # predecessores por \u00edndice (n\u00f3s que apontam para i)\n    predecessors = {\n        i: [idx[p] for p in G.predecessors(nodes[i])]\n        for i in range(N)\n    }\n\n    base = (1.0 - d) / N\n\n    # itera\u00e7\u00f5es\n    for _ in range(max_iter):\n        pr_new = np.full(N, base, dtype=float)\n\n        # contribui\u00e7\u00e3o de n\u00f3s dangling (sem sa\u00edda)\n        dangling_sum = pr[out_deg == 0].sum()\n        pr_new += d * dangling_sum / N\n\n        # contribui\u00e7\u00e3o dos predecessores\n        for i in range(N):\n            s = 0.0\n            for j in predecessors[i]:\n                if out_deg[j] &gt; 0:\n                    s += pr[j] / out_deg[j]\n            pr_new[i] += d * s\n\n        # crit\u00e9rio de parada\n        if np.max(np.abs(pr_new - pr)) &lt; tol:\n            pr = pr_new\n            break\n\n        pr = pr_new\n\n    # converte para dict {n\u00f3: score}\n    pr_dict = {nodes[i]: float(pr[i]) for i in range(N)}\n    return pr_dict\n\n\n# ----------------------------------------------------------------------\n# Script principal: roda para d = 0.5, 0.85, 0.99 e printa resultados\n# ----------------------------------------------------------------------\n# Caminho do arquivo roadNet-CA (ajuste se necess\u00e1rio)\npath = \"./docs/pageRank/roadNet-CA.txt\"\n\n# Carrega o grafo como DiGraph\nG = nx.read_edgelist(\n    path,\n    comments=\"#\",\n    nodetype=int,\n    create_using=nx.DiGraph()\n)\n\n# Valores de d a serem testados\nd_values = [0.5, 0.85, 0.99]\n\nfor d in d_values:\n    pr_dict = pagerank_custom(G, d=d, tol=1e-4, max_iter=100)\n\n    pr_values = np.fromiter(pr_dict.values(), dtype=float)\n\n    print(f\"\\n==================== RESULTADOS PARA d = {d} ====================\")\n    print(f\"\\nSoma dos PR: {pr_values.sum():.6f}\")\n    print(f\"\\nPR m\u00ednimo:  {pr_values.min():.6e}\")\n    print(f\"\\nPR m\u00e1ximo:  {pr_values.max():.6e}\")\n\n    # Top-10 n\u00f3s\n    top10 = sorted(pr_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n\n    print(\"\\nTop-10 n\u00f3s por PageRank:\")\n    for i, (node, score) in enumerate(top10, 1):\n        print(f\"\\n{i:2d}. n\u00f3={node} | PR={score:.6e}\")\n</code></pre> <p>A an\u00e1lise das tr\u00eas varia\u00e7\u00f5es do fator de amortecimento (d = 0.5, 0.85 e 0.99) mostra que, embora os valores de PageRank sofram pequenas altera\u00e7\u00f5es num\u00e9ricas conforme o peso dado ao \u201cteleporte\u201d aumenta ou diminui, o ranking dos n\u00f3s permanece essencialmente est\u00e1vel. Em todas as configura\u00e7\u00f5es, o n\u00f3 225438 ocupa a primeira posi\u00e7\u00e3o, seguido pelos n\u00f3s 287362, 241926, 748883 e 1682326, indicando que esses v\u00e9rtices s\u00e3o estruturalmente centrais na malha vi\u00e1ria independentemente do comportamento do caminhante aleat\u00f3rio. Observa-se que, para valores menores de d (como 0.5), o PageRank tende a se distribuir de forma mais uniforme, reduzindo a diferen\u00e7a entre os n\u00f3s de maior e menor import\u00e2ncia. J\u00e1 para valores mais altos (como 0.99), a influ\u00eancia da topologia se intensifica, ampliando levemente as diferen\u00e7as entre os n\u00f3s de maior conectividade. Apesar disso, o conjunto de n\u00f3s mais influentes n\u00e3o se altera, o que demonstra que a rede possui uma estrutura robusta de hubs e que o PageRank \u00e9 bastante est\u00e1vel em rela\u00e7\u00e3o \u00e0 escolha do fator de amortecimento neste grafo.</p>"},{"location":"pageRank/main/#8-analise-final","title":"8. An\u00e1lise Final","text":"<p>Em s\u00edntese, os experimentos realizados demonstram que a implementa\u00e7\u00e3o manual do PageRank \u00e9 plenamente consistente com a solu\u00e7\u00e3o consolidada do NetworkX, validando a corretude do algoritmo desenvolvido. Al\u00e9m disso, a an\u00e1lise das diferentes configura\u00e7\u00f5es do fator de amortecimento evidencia que, embora os valores absolutos de PageRank variem conforme a probabilidade de teleporte, o conjunto de n\u00f3s mais influentes permanece est\u00e1vel em todas as execu\u00e7\u00f5es, revelando a presen\u00e7a de estruturas centrais bem definidas na malha vi\u00e1ria do roadNet-CA. Isso refor\u00e7a a robustez do PageRank como m\u00e9trica de import\u00e2ncia em redes reais e mostra que a conectividade intr\u00ednseca do grafo exerce maior impacto no ranking do que ajustes finos no par\u00e2metro d. Dessa forma, os resultados obtidos fornecem uma caracteriza\u00e7\u00e3o consistente dos principais hubs da rede e confirmam a confiabilidade tanto da abordagem manual quanto das ferramentas de an\u00e1lise oferecidas por bibliotecas especializadas.</p>"},{"location":"pySpark/main/","title":"pySpark","text":""},{"location":"pySpark/main/#pyspark","title":"PySpark","text":""},{"location":"randomForest/main/","title":"Random Forest","text":""},{"location":"randomForest/main/#objetivo","title":"Objetivo","text":"<p>O objetivo geral deste roteiro \u00e9 utilizar as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>, al\u00e9m de uma base escolhida no Kagle, para treinar e avaliar um algoritmo de Random Tree.</p>"},{"location":"randomForest/main/#base-de-dados","title":"Base de Dados","text":"<p>A base de dados escolhida para a realiza\u00e7\u00e3o deste roteiro foi a MBA Admission Dataset. Esta base possui 6194 linhas e 10 colunas, incluido uma coluna de ID da aplica\u00e7\u00e3o e uma coluna de status da admiss\u00e3o, esta \u00e9 a v\u00e1riavel dependente que ser\u00e1 objeto da classifica\u00e7\u00e3o.</p>"},{"location":"randomForest/main/#analise-da-base","title":"An\u00e1lise da Base","text":"<p>A seguir foi feita uma an\u00e1lise do significado e composi\u00e7\u00e3o de cada coluna presente na base com a finalidade de indentificar poss\u00edveis problemas \u00e1 serem tradados posteriormente. </p> application_idgenderinternationalgpamajorracegmatwork_expwork_industryadmission <p>Esta coluna \u00e9 composta pelos ID's das aplica\u00e7\u00f5es realizadas, ou seja trata-se de um valor num\u00e9rico l\u00f3gico, \u00fanico a cada aplica\u00e7\u00e3o, desta forma pode-se afirmar que esta coluna n\u00e3o ter\u00e1 relev\u00e2ncia para o algoritmo e dever\u00e1 ser retirada da base para treinamento.</p> 2025-12-04T02:33:57.911220 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com o gen\u00earo do aplicante, contendo apenas valores textuais entre \"male\" e \"female\", n\u00e3o incluindo op\u00e7\u00f5es como \"non-binary\", \"other\" ou \"prefer not to inform\". Logo, estes dados, por serem textuais e apresentarem binariedade, dever\u00e3o ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> 2025-12-04T02:33:57.990798 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna \u00e9 preenchida com valores booleanos que classificam o aplicantente como \"estrangeiro\" ou \"n\u00e3o-estrangeiro\". Logo, estes dados, por serem textuais e apresentarem binariedade, deveriam ser transformados em uma vari\u00e1vel dummy para que se atinja um melhor desempenho do algoritmo.</p> <p>Entretanto, a classifica\u00e7\u00e3o desta coluna tambem poder ser notada na coluna \"race\", pois todos os valores nulos presentes na posterior s\u00e3o unicamente referentes a alunos estrangeiros.</p> 2025-12-04T02:33:58.022763 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a performance acad\u00eamica pr\u00e9via do aplicante, que \u00e9 calculada a partir do hist\u00f3rico escolar. Neste as notas particulares de cada mat\u00e9ria podem variar de 0 \u00e1 4, 0 sendo a pior nota poss\u00edvel e 4 a maior. Neste caso os GPA's dos aplicantes variam entre 2.65 e 3.77, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-12-04T02:33:58.058950 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa em que curso o aplicante deseja entrar, podendo assumir um de tr\u00eas valores textuais: \"Humanities\", \"STEM\" e \"Business\". Neste caso, como a variavel \u00e9 textual e n\u00e3o apresenta binariedade, a t\u00e9cnica correta para o tratamento desta coluna ser\u00e1 o Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-12-04T02:33:58.133917 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a indentifica\u00e7\u00e3o racial do aplicante, por\u00e9m tambem h\u00e1 diversas linhas com valor nulo nesta coluna. Ao comparar o preenchimento desta coluna com as demais, percebe-se que o valor desta coluna so se apresenta nulo para estudantes estrangeiros, tornando a coluna \"international\" redundante.</p> <p>Desta forma, para otimizar o modelo, devemos remover a coluna \"international\", prezando pela menor quantidade de colunas poss\u00edvel. E como esta coluna n\u00e3o apresentar binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais e nulos em valores n\u00famericos. </p> 2025-12-04T02:33:58.172942 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o desempenho do aplicante na prova de adimiss\u00e3o, variando de 570 \u00e1 780, por\u00e9m estas notas n\u00e3o apresentam uma curva normal, pois h\u00e1 muitos registros de notas menores que a m\u00e9dia a mais do que h\u00e1 registos de notas maiores que a m\u00e9dia. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-12-04T02:33:58.217872 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa o tempo de experi\u00eancia pr\u00e9via do aplicante no mercado, exibida em anos. Os valores podem variar de 1 \u00e1 9, apresentando uma curva normal. Devido ao fato destes valores j\u00e1 serem num\u00e9ricos estes j\u00e1 est\u00e3o adequados para o modelo.</p> 2025-12-04T02:33:58.303596 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna representa a \u00e1rea de experi\u00eancia pr\u00e9via do aplicante no mercado, podendo assumir, nesta base um de quatorze valores textuais. E como esta coluna n\u00e3o apresenta binariedade, dever\u00e1 ser utilizada a t\u00e9cnica de Label Enconding, transformando estes valores textuais em valores n\u00famericos.</p> 2025-12-04T02:33:58.391013 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Esta coluna apresenta valores em texto para os aplicantes admitos e na lista de espera, al\u00e9m de valores nulos para aqueles que n\u00e3o foram aceitos. Esta coluna \u00e9 o objeto da classifica\u00e7\u00e3o e portanto ser\u00e1 separada das outras colunas da base, e os valores nulos deveram ser preenchidos.</p> 2025-12-04T02:33:58.497703 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"randomForest/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Esta sec\u00e7\u00e3o visa preparar os dados para o treinamento da \u00e1rvore de decis\u00e3o, atendendo as observa\u00e7\u00f5es e an\u00e1lises feitas no t\u00f3pico anterior.</p> Base preparadacodeBase original gender gpa major race gmat work_exp work_industry admission 1 2.99 0 5 640 5 1 Refused 1 3.38 0 4 680 4 13 Refused 1 3.32 1 1 660 5 1 Refused 1 3 1 0 610 4 5 Refused 0 3.32 2 1 670 4 8 Refused 1 3.04 2 4 600 3 1 Refused 0 3.15 2 5 580 6 1 Refused 0 3.07 2 5 650 5 1 Refused 1 3.31 2 3 630 6 9 Refused <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\nprint(df.sample(frac=.0015).to_markdown(index=False))\n</code></pre> application_id gender international gpa major race gmat work_exp work_industry admission 5193 Male True 3.24 Business nan 630 5 Nonprofit/Gov nan 3152 Male True 3.41 Humanities nan 770 5 Investment Management nan 288 Male False 3.14 Business Hispanic 580 2 PE/VC nan 3619 Male False 3.34 Business Other 650 5 Other nan 3925 Female False 3.16 Business White 670 5 PE/VC nan 2946 Male True 3.01 Humanities nan 570 5 Consulting nan 4248 Male False 3.42 STEM Hispanic 690 4 Health Care nan 5474 Female False 3.53 Business Black 650 5 Other nan 191 Female False 3.32 Humanities White 730 5 Nonprofit/Gov Admit"},{"location":"randomForest/main/#divisao-dos-dados","title":"Divis\u00e3o dos dados","text":"<p>Devido a composi\u00e7\u00e3o da coluna de admission, a sepera\u00e7\u00e3o dos dados deve ser feita com maior aten\u00e7\u00e3o. Caso esta separa\u00e7\u00e3o fosse feita com aleatoriedade, haveria a possibilidade de que a base de treinamento tornar-se enviesada. Portanto, esta deve ser executada com proporcionalidade a composi\u00e7\u00e3o da coluna alvo. Tendo em vista situa\u00e7\u00f5es como esta o <code>sickit-learn</code> j\u00e1 implementou o sorteamento extratificado como a op\u00e7\u00e3o <code>stratify</code> no comando <code>train_test_split()</code>.</p> <p>Al\u00e9m disto para o treinamento foi utilizado uma separa\u00e7\u00e3o arbitr\u00e1ria da base em 70% treinamento e 30% valida\u00e7\u00e3o.</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nlabel_encoder = LabelEncoder()\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=27, stratify=y)\n</code></pre>"},{"location":"randomForest/main/#treinamento-da-arvore","title":"Treinamento da \u00c1rvore","text":"Modelo da \u00c1rvorecode <p>Accuracy: 0.8386 Import\u00e2ncia das Features:  Feature Import\u00e2ncia 4 gmat 0.519098 1 gpa 0.322064 0 gender 0.064424 3 race 0.035490 6 work_industry 0.028160 5 work_exp 0.021203 2 major 0.009562 </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nlabel_encoder = LabelEncoder()\n\n\ndf = pd.read_csv(\"./docs/base/MBA.csv\")\n\n#Excluir as conlunas n\u00e3o desejadas\ndf = df.drop(columns= [\"application_id\", \"international\"])\n\n#Preencher os valores nulos da coluna \"race\"\ndf[\"race\"] = df[\"race\"].fillna(\"international\")\n\n#Preencher os valores nulos da coluna \"admission\"\ndf[\"admission\"] = df[\"admission\"].fillna(\"Refused\")\n\n#Label encoding das colunas em texto\ndf[\"race\"] = label_encoder.fit_transform(df[\"race\"])\ndf[\"gender\"] = label_encoder.fit_transform(df[\"gender\"])\ndf[\"major\"] = label_encoder.fit_transform(df[\"major\"])\ndf[\"work_industry\"] = label_encoder.fit_transform(df[\"work_industry\"])\n\n#Separar em vairaveis indenpendetes e dependente\nx = df[[\"gender\", \"gpa\", \"major\", \"race\", \"gmat\", \"work_exp\", \"work_industry\"]]\ny = df[\"admission\"]\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Initialize and train the model\nrf = RandomForestClassifier(n_estimators=100,  # Number of trees\n                            max_depth=5,       # Max depth of trees\n                            max_features='sqrt',  # Features per split\n                            random_state=42)\nrf.fit(X_train, y_train)\n\n# Predict and evaluate\npredictions = rf.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n\nfeature_importance = pd.DataFrame({\n    'Feature': rf.feature_names_in_,\n    'Import\u00e2ncia': rf.feature_importances_\n})\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.sort_values(by='Import\u00e2ncia', ascending=False).to_html())\n</code></pre>"},{"location":"randomForest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Com este treinamento o modelo apresenta 78.48% de precis\u00e3o, n\u00famero satisfat\u00f3rio para um modelo de classifica\u00e7\u00e3o real, e as colunas mais importantes em sua tomada de deicis\u00e3o s\u00e3o as ponuta\u00e7\u00f5es gmat e gpa com 51.9% e 32.2% de import\u00e2ncia, respectivamente, e a coluna com menor relevancia para o modelo \u00e9 a major, com  0.9% de import\u00e2ncia.</p>"},{"location":"randomForest/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O processo de treinamento da Random Forest consistiu em preparar os dados (remo\u00e7\u00e3o de application_id, codifica\u00e7\u00f5es e alinhamento dos tipos), separar a base em 70% treino e 30% valida\u00e7\u00e3o com estratifica\u00e7\u00e3o pela coluna admission, e ent\u00e3o ajustar um comit\u00ea de \u00e1rvores de decis\u00e3o: cada \u00e1rvore foi treinada em bootstraps do conjunto de treino e, a cada divis\u00e3o, considerou apenas um subconjunto aleat\u00f3rio de vari\u00e1veis, o que reduz correla\u00e7\u00e3o entre \u00e1rvores e estabiliza o erro. A previs\u00e3o final resulta do voto majorit\u00e1rio entre as \u00e1rvores. A avalia\u00e7\u00e3o do modelo obteve 78,48% de acur\u00e1cia, e as import\u00e2ncias de atributos, calculadas pelo ganho m\u00e9dio de impureza ao longo das divis\u00f5es, indicaram GMAT (51,9%) e GPA (32,2%) como os preditores mais influentes, enquanto major apresentou baixa relev\u00e2ncia (0,9%).</p>"}]}